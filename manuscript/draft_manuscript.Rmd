---
title: "How many researchers use 'boilerplate' statistical analysis sections?"
author: "Nicole White, Thiru Balasubramaniam, Richi Nayak, Adrian Barnett"
date: "21/05/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
link-citations: yes
bibliography: references.bib
subtitle: An observational study of papers published in _PLOS ONE_.
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(tidyr)
library(pander)
library(ggplot2)
library(ggpubr)
panderOptions('table.emphasize.rownames', FALSE)
panderOptions('keep.trailing.zeros', TRUE)
panderOptions('table.split.table', Inf)
panderOptions('table.split.cells', Inf)
panderOptions('big.mark', ',')
panderOptions('table.emphasize.rownames', FALSE)
panderOptions('keep.trailing.zeros', TRUE)
panderOptions('table.split.table', Inf)
panderOptions('table.split.cells', Inf)
panderOptions('big.mark', ',')
panderOptions('keep.line.breaks', TRUE)
panderOptions('table.alignment.default','left')

g.theme = theme_bw()+theme(legend.position = 'top',legend.direction = 'horizontal',
                           axis.text = element_text(size=12),axis.text.x = element_text(size=12),axis.text.y = element_text(size=12))
```

An ideal statistical analysis will use appropriate methods to create insights from the data and inform the research questions. Unfortunately many current statistical analyses are far from ideal, with many researchers using the wrong methods, misinterpreting the results, or failing to adequately check their assumptions [@Goodman2008;@Leek2017]. Some researchers take a "mechanistic" approach to statistics, copying the few methods they know regardless of their appropriateness, and then going through the motions of the analysis [@Stark2018]. 

Many researchers lack adequate training in research methods, and statistics is something they do with trepidation and even ignorance [@Altman1994;@King2019]. 
However, using the wrong statistical methods can cause real harm [@Altman1994] and bad statistical practices are being to used abet weak science [@Stark2018].
Statistical mistakes are a key source of waste in research and partly explain the current reproducibility crisis in science [@Allison2016]. Even when the correct methods are used, many researchers fail to describe them adequately, making it difficult to reproduce the results [@Ernst2017;@Zhou2018].

The International Committee of Medical Journal Editors recommend that researchers should: “Describe statistical methods with enough detail to enable a knowledgeable reader with access to the original data to judge its appropriateness for the study and to verify the reported results” [@ICMJE2019]. Although the general lack of statistical understanding from both authors and reviewers means this recommendation may not be checked.
A recent survey of editors found that only 23% of health and medical journals used expert statistical review for all articles [@Hardwicke2020], which was little different from a survey from 22 years ago [@Goodman1998].

Two statisticians on this paper (AB and NW) have heard researchers admit that they sometimes copy-and-paste their statistical methods sections from other papers, regardless of whether they are appropriate. 
The aim of this paper is to use text-mining methods to estimate the extent that researchers are using cut-and-paste or 'boilerplate' statistical methods sections.
Use of these methods sections indicates that little thought has gone into the statistical analysis.


# Methods

## Data sources

We used two openly available data sources to find statistical methods sections.

### Public Library of Science (PLOS ONE)

_PLOS ONE_ is a large open access journal that publishes original research across a wide range of scientific fields. Articles must be in English. Article submissions are handled by an academic editor who selects peer reviewers based on their self-nominated area(s) of expertise. Submissions do not undergo formal statistical review. Instead, reviewers are required to assess submissions against several publication criteria, including whether: “Experiments, statistics, and other analyses are performed to a high technical standard and are described in sufficient detail”. Authors are encouraged to follow published reporting guidelines to ensure that chosen statistical methods are appropriate for the study design, and adequate details are provided to enable independent replication of results. Reporting guidelines are available from the EQUATOR network which has developed guidelines for study designs commonly used in health research, and these guidelines were developed to tackle poor statistical application and reporting in health and medical journals [@Altman2016].

All _PLOS ONE_ articles are freely accessible via the PLOS Application Programming Interface (API). This functionality enabled us to conduct semi-automated searches of full-text articles and analyse data on individual records, including text content and general attributes such as publication date and field(s) of research. To find papers with a statistical methods section we used targeted API searches followed by article filtering based on section headings. The data were downloaded on xx-xxxx-xxx.

_Step 1_: Targeted API searches. API searches were completed using the R package ‘rplos’ [@rplos]. Search queries targeted the presence of analysis-related terms anywhere in the article. Search terms combined the words “data” or “statistical” with one of: “analysis”, “analyses”, “method”, “methodology” or “model(l)ing”. Search terms were intended to be broad whilst keeping search results to a manageable number for full-text review (see Step 2). By allowing terms to appear anywhere within the article, we accounted for the possibility of relevant text being placed in different sections, for example, in the _Material and Methods_ section versus _Results_. Search results were indexed by a unique Digital Object Identifier (DOI). Attribute data collected per DOI included journal volume, subject classification(s) and total article views since publication.

_Step 2_: Partial matching on section headings. Full text XML data for all search results were downloaded and combined into a single dataset, organised by DOI and subsection heading(s). Since _PLOS ONE_ does not prescribe standardised headings to preface statistical methods sections, we performed partial matching on available headings against frequently used terms in initial search results: ‘Statistical analysis’, ‘Statistical analyses’, ‘Statistical method’, ‘Statistics’, ‘Data analysis’ and ‘Data analyses’. To determine the reliability of our chosen filters, we manually reviewed full text data extracted for a random sample of XXX articles that were not matched (File S1).[TODO…finish this thought…]

### Australia and New Zealand Clinical Trials Registry (ANZCTR)

The ANZCTR was established in 2005 as part of a coordinated global effort to improve research quality and transparency in clinical trials reporting; observational studies can also be registered. All studies registered on ANZCTR are publicly available and can be searched via an online portal (https://www.anzctr.org.au/). 
<!--- Researchers responsible for overseeing a clinical trial are expected to register full details before commencing participant enrolment. --->
Details required for registration follow a standardised template (reference or supp file), which covers participant eligibility, the intervention(s) being evaluated, study design and outcomes. Researchers are asked to provide a "brief description" of the sample size calculations, statistical methods and planned analyses, although this section is not compulsory [@ANZCTR]. The information provided must be in English. Studies are reviewed by ANZCTR staff for completeness of key information, which does not include the completeness of the statistical methods sections. Studies are not peer reviewed. 
<!---Upon successful registration, the trial is assigned a unique registration number for use in future reporting in scientific publications. --->

All studies available on ANZCTR were downloaded on 1 February 2020 in XML format. 
We used all the text available in the "Statistical methods" section. We also collated basic information about the study including the study type (interventional or observational), submission date, number of funders and target sample size. These variables were chosen as we believed they might influence the completeness of the statistical methods section, because we expected larger studies and those with funding to be more complete, and we also were interested in changes over time.
Studies prior to 2013 were excluded as the statistical methods section appeared to be introduced in 2013.
Some studies were first registered on the alternative trial database _clinicaltrials.gov_ and then also posted to ANZCTR. We excluded these studies because they almost all had no completed statistical methods section as this requested by _clinicaltrials.gov_.

## Full-text processing

Text cleaning aimed to standardise notation and statistical terminology, whilst minimising changes to article style and formatting. Full details of text cleaning steps undertaken and corresponding R code are provided in Supplementary File X.

Mathematical notation including Greek letters was converted from Unicode characters to plain text. For example, the Unicode characters corresponding to $\theta$ (<U+03B8>) was replaced with ‘theta’. Similarly, common symbols outside of Unicode blocks including ‘%’ (percent) and ‘<’ (‘less-than’) were converted into plain text, using functions available in the ‘textclean’ package [@textclean]. General formatting was removed, this included carriage returns, punctuation marks, in-text references (e.g. "[42]") centred equations, and other non-ascii characters. Text contained inside brackets was retained in the dataset to maximise content for analysis, with brackets removed.

We compiled an extensive list of statistical terms to standardise descriptions of statistical methods reported across both datasets. An initial list was compiled by calculating individual word frequencies and identifying relevant terms that appeared at least 100 times. Further terms were sourced from index searches of statistics reference textbooks [ref]. The final list is provided as Supplementary Material. Possible variants including plurals (e.g. ‘chi-squares’) unhyphenated (e.g ‘chi square’) and combined (e.g. ‘chisquare’) terms were transformed to singular, hyphenated form (e.g ‘chi-square’). Common statistical tests were also hyphenated (e.g. ‘hosmer lemeshow’ to ‘hosmer-lemeshow’).

As a final step, common stop words including pronouns, contractions and selected prepositions were removed. We retained selected stop words that, if excluded, may have changed the context of statistical method(s) being described, for example ‘between’ and ‘against’.

<!-- Questions: -->

<!-- * What questions are asked of PLOS ONE Reviewers? -->

<!-- - Is the manuscript technically sound, and do the data support the conclusions? -->
<!-- - Has the statistical analysis been performed appropriately and rigorously? -->
<!-- - Does the manuscript adhere to the PLOS Data Policy? -->
<!-- - Is the manuscript presented in an intelligible fashioin and written in standard English? -->


<!-- * Reference updates to stats reporting guidelines; e.g see: -->

<!-- - https://everyone.plos.org/2019/09/26/new-plos-one-statistical-reporting-guidelines/. -->
<!-- - https://web.archive.org/web/20190607174803/https://journals.plos.org/plosone/s/submission-guidelines -->
<!-- - https://web.archive.org/web/20150507175314/https://journals.plos.org/plosone/s/submission-guidelines -->


## Clustering algorithm

## Missing statistical methods sections

The statistical methods section for the ANZCTR data was somtimes missing and so we examined if there were particular studies where this section was more likely to be missing. 
We used a logistic regression model fitted using a Bayesian paradigm. A small number of sections were labelled as "Not applicable", "Nil" or "None" and we changed these to missing. 

# Results

## PLOS ONE

```{r}
load('total.records.plos.rda')
n.api = total.records[[1]] %>% filter(stage=='API') %>% pull(n) %>% sum()
n.include = total.records[[1]] %>% filter(stage=='Included in analysis') %>% pull(n) %>% sum()
perc.include = round(100*n.include/n.api)
min.perc.stats = total.records[[2]] %>% filter(percentage==min(percentage)) %>% select(volume,percentage)
max.perc.stats = total.records[[2]] %>% filter(percentage==max(percentage)) %>% select(volume,percentage)

```

```{r}
load('wordcount.plos.rda')
n.words = wordcounts %>% summarise(med = median(words),q1=quantile(words,.25),q3=quantile(words,.75))
```



```{r,fig.width=10,fig.height=12,fig.cap='\\label{fig:plos-n}Search results by PLOS ONE volume (1st row); word count per statistical methods section included in analysis (n = 111,731; 2nd row); subject classifications assigned to full-text records included in analysis (3rd row)'}
to_plot = total.records[[2]] %>% select(-percentage) %>% gather(variable,value,-volume) %>%
  mutate(variable=factor(variable,levels=c('API','Included in analysis')))

g1 = ggplot(to_plot,aes(x=volume,y=value,fill=variable))+geom_bar(stat='identity',position='dodge',width=0.9,colour='black')+scale_y_continuous('Total records',breaks=seq(0,20000,2500))+
  scale_x_continuous('Volume',breaks=1:15)+scale_fill_grey(guide = guide_legend(reverse = TRUE) )+g.theme+theme(legend.title = element_blank())

g2 = ggplot(wordcounts,aes(y=log10(words),x=volume,group=volume))+geom_boxplot()+
  scale_x_continuous('Volume',breaks=1:14)+scale_y_continuous('Word count (log10 transformed)',breaks=seq(0,4,0.5))+g.theme

load('stats_section_subject.classifications.rda')
stats_section_subject = mutate(stats_section_subject,
top3 = ifelse(subject_level_number %in% 1:3,1,0))
to_plot = stats_section_subject %>% group_by(subject_level_name) %>% summarise(n=n(),Yes=sum(top3),No=sum(top3==0),.groups='drop')

to_plot.bar = to_plot %>% arrange(-n) %>% select(-n) %>% gather('Top 3 subject classification',value,-subject_level_name) %>%
mutate(subject_level_name=factor(subject_level_name,levels=rev(unique(subject_level_name))),
'Top 3 subject classification'=factor(`Top 3 subject classification`,levels = c('No','Yes')))
  
  
g3 = ggplot(to_plot.bar,aes(x=subject_level_name,y=value/10000,fill=`Top 3 subject classification`))+geom_bar(stat='identity',colour='black',width=0.75)+scale_y_continuous('Total records (x 10,000)',breaks=seq(0,12,1))+xlab('')+coord_flip()+scale_fill_manual(values = c('grey75','grey15'))+ theme_bw() + theme(legend.position = 'top',
legend.direction = 'horizontal',axis.text = element_text(size=12),axis.text.x = element_text(size=12),axis.text.y = element_text(size=12))

ggarrange(g1,g2,g3,nrow=3,labels=LETTERS[1:3])
  

n.top3 = to_plot %>% filter(n==Yes)
n.biology = to_plot %>% filter(subject_level_name=='Biology and life sciences') %>% pull(n)
n.earth = to_plot %>% filter(subject_level_name=='Earth sciences') %>% pull(n)
n.computer = to_plot %>% filter(subject_level_name=='Computer and information sciences') %>% pull(n)

```


API searches returned `r n.api` unique records, of which `r n.include` (`r perc.include`%) included a statistical methods section based on our search criteria. Search results varied by journal volume (Figure 1A). The total number of API search results peaked at volumes 8 (n = `r total.records[[2]] %>% filter(volume==8) %>% pull(API)`) and 9 (n = `r total.records[[2]] %>% filter(volume==8) %>% pull(API)`), corresponding to years 2013 and 2014. This trend aligned with the total number of papers published in PLOS ONE over the same timeframe. The percentage of records that included a statistical methods section by volume based on our proposed matching criteria varied between `r round(min.perc.stats[['percentage']])`% (volume `r min.perc.stats[['volume']]`) and `r round(max.perc.stats[['percentage']])`% (volume `r max.perc.stats[['volume']]`).

The median length of statistical methods sections after text cleaning was `r n.words[['med']]` per DOI (IQR: `r n.words[['q1']]` to `r n.words[['q3']]`) (Figure 1B).

Across all records included in analysis, all included Biology and life sciences (n = `r n.biology`), Earth sciences
(n = `r n.earth`) and/or Computer and information sciences (n = `r n.computer`) within their top 3 subject classifications
(Figure 1C).

[Figure here or as supplementary - 5 topic solution]

Results of topic modelling assuming five clusters showed clear separation between statistical software, hypothesis testing and linear modelling (Figure). The largest cluster, representing 48% of all included studies (Topic 2, n = 53,491).

Two topics (26% of study sample) were dominated by terms related statistical software, notably Prism/GraphPad (Topic 3, n = 10,940) and SPSS (Topic 5, n = 18,029). Remaining topics focussed on hypothesis testing (Topic, n = 12,531) and analysis of variance/multiple comparisons (Topic 4, n = 16,740)

Top matches (Topic 3)

* 10.1371/journal.pone.0043519: All statistical analyses were performed using GraphPad Prism (GraphPad Software Inc., San Diego, CA).
* 10.1371/journal.pone.0045453: GraphPad Prism (Graphpad Software, San Diego, CA) was used for all analyses.
* 10.1371/journal.pone.0170640: All statistical analysis of the data was performed using GraphPad Prism software (GraphPad Prism Software Inc., La Jolla, Ca).
* 10.1371/journal.pone.0036750: All statistical analysis was performed using Graphpad Prism software.
* 10.1371/journal.pone.0058148: All statistical analysis was performed using the Graphpad Prism software.


Top matches (Topic 5)
* 10.1371/journal.pone.0120046: Statistical analysis was performed using the SPSS version 18.0 (SPSS Inc., Chicago, IL, USA). Mann-Whitney test was used for the analysis of continuous variables. Chi-square test, Fisher’s exact test or one-way ANOVA test was employed for the analysis of categorical variables. P < 0.05 was considered statistically significant.

* 10.1371/journal.pone.0204950: Statistical analyses were performed using SPSS version 20.0 for Windows (SPSS Inc., Chicago, IL). Categorical and continuous variables were evaluated with the non-parametric chi-square test, the Kruskal-Wallis test, and the Mann-Whitney U test. All statistical tests were two-sided, and a p value <0.05 was considered statistically significant.

* 10.1371/journal.pone.0062685: SPSS version 21.0 for Windows (SPSS, Inc., Chicago, IL, USA) was used for statistical analysis. Categorical variables were analyzed by a chi-square test or Fisher’s exact test. Continuous variables were analyzed by independent t-test or Mann-Whitney test. Logistic regression analysis was performed to evaluate the effects of independent variables on clinical outcomes. A p-value of <0.05 by the two-tailed test was considered statistically significant.

* 10.1371/journal.pone.0133783: Data are expressed as means ± SD or medians (with interquartile ranges). Statistical analyses were performed using SPSS software version 19.0 (SPSS, Inc., Chicago, IL, USA). Statistical significance for intergroup differences was assessed by the χ2 test or Fisher’s exact test for categorical variables, and by the Student’s t-test, or Mann–Whitney U test for continuous variables. Correlations between variables were tested with Spearman’s correlation analysis. A P-value <0.05 was considered significant for all tests.

* 10.1371/journal.pone.0098797: Univariate analysis was performed using Mann–Whitney U-tests for continuous variables and Pearson's chi-square or Fisher's exact tests for categorical variables. Statistical significance was set at a P-value <0.05. SPSS statistical software version 19 (SPSS, Chicago, IL, USA) was used to perform the statistical analyses.

[Figure here or as supplementary - 10 topic solution]


## ANZCTR

We downloaded 28,008 studies. The numbers of excluded studies are shown in Figure~X. 
Of the 12,700 included studies, 9,523 had a statistic section which is 75% (95% CI 74% to 76%). 

We examined if four study characteristics were associated with a missing statistics section. The odds ratios and 95% credible intervals are in Table~X. Observational studies were less likely to have a missing methods section compared with interventional studies. Missing sections became less likely over time. Studies with more funders and a larger target sample size were less likely to have a missing methods section.  

Variable & Odds ratio & 95% CI
Study type = Observational & 0.78 & 0.69, 0.89
Date (per year) & 0.90 & 0.88, 0.91
Number of funders & 0.80 & 0.74, 0.86
Target sample size (per doubling) & 0.90 & 0.88, 0.92

Some of the non-missing statistics sections were only one word, including "ANOVA", "t-test", "SPSS" and even "SSPS". The median length of the section was 129 words with an inter-quartile range of 71 to 219 words.

* Final sample size

# Discussion

The first line in many statistical analysis sections in _PLOS ONE_ was the software used and some entire sections in ANZCTR only stated the software, implying that the software is the most important detail. As Doug Altman said, "Many people think that all you need to do statistics is a computer and appropriate software" [@Altman1994]. This is not the case, and whilst it is important for researchers to mention the software and version used for reproducibility purposes, it is a minor detail compared with detailing what methods were used and why.

Despite the extensive array of statistical tests available, many authors are reporting the same few methods.

One reason these inadequate sections get published is that most journals do not use statistical reviewers, despite empirical evidence showing they improve manuscript quality [@Hardwicke2020]. 

## Limitations

We did not check whether papers used the correct methods, and for some simple studies a 'boilerplate' statistical methods section would be fine.

We examined papers where there was a statistics section, and we missed papers that used statistical analysis but did not include a statistical analysis section. Reiterate outcomes of random sample checking here.

We only examined one journal and one trial registry and hence our results may not be generalisable to all journals or registries, especially those that consistently use a statistical reviewer.

We searched the full text of _PLOS ONE_ papers but not the supporting information which may contain statistical methods sections for some papers. The search terms we used to find statistical methods appeared in the supporting information titles for xxx papers (x%). We did not include the supporting information because it is less structured than the paper and could be in PDF or Word format.

# References

