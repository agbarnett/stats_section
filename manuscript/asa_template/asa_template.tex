% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here



% Pandoc citation processing

\usepackage{pdflscape}

\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf An observational study of papers published in \emph{PLOS ONE} and
studies posted to a trial registry.}

  \author{
        Nicole White \thanks{The authors gratefully acknowledge computational resources and services
used in this work provided by the eResearch Office, Queensland
University of Technology, Brisbane, Australia.} \\
    School of Public Health and Social Work, QUT\\
     and \\     Thiru Balasubramaniam, Richi Nayak \\
    To add\\
     and \\     Adrian Barnett \\
    School of Public Health and Social Work, QUT\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf An observational study of papers published in \emph{PLOS ONE} and
studies posted to a trial registry.}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
The text of your abstract. 200 or fewer words.
\end{abstract}

\noindent%
{\it Keywords:} 3 to 6 keywords, that do not appear in the title
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

An ideal statistical analysis will use appropriate methods to create
insights from the data and inform the research questions. Unfortunately
many current statistical analyses are far from ideal, with many
researchers using the wrong methods, misinterpreting the results, or
failing to adequately check their assumptions \citep{2008, Leek2017}.
Some researchers take a ``mechanistic'' approach to statistics, copying
the few methods they know regardless of their appropriateness, and then
going through the motions of the analysis \citep{Stark2018}.

Many researchers lack adequate training in research methods, and
statistics is something they do with trepidation and even ignorance
\citep{Altman1994, King2019}. However, using the wrong statistical
methods can cause real harm \citep{Altman1994, Brown2018} and bad
statistical practices are being to used abet weak science
\citep{Stark2018}. Statistical mistakes are a key source of waste in
research and partly explain the current reproducibility crisis in
science \citep{Allison2016}. Even when the correct methods are used,
many researchers fail to describe them adequately, making it difficult
to reproduce the results \citep{Ernst2017, Zhou2018}. Poor statistical
methods might not be caught by reviewers, as they may not be qualified
to judge the statistics. A recent survey of editors found that only 23\%
of health and medical journals used expert statistical review for all
articles \citep{Hardwicke2020}, which was little different from a survey
from 22 years ago \citep{Goodman1998}.

There is guidance for researchers on how to write up their statistical
methods and results. The International Committee of Medical Journal
Editors recommend that researchers should: ``Describe statistical
methods with enough detail to enable a knowledgeable reader with access
to the original data to judge its appropriateness for the study and to
verify the reported results'' \citep{ICMJE2019}. More detailed guideance
is given by the SAMPL and EQUATOR guidelines
\citep{Lang2013, Altman2016} with the latter covering all apsects of the
paper. Both of these guidelines were led by Doug Altman, who spoke often
and for many years about the need for better statistical reporting. The
awareness and use of these guidelines could be improved. There were 256
Google Scholar citations to the SAMPL paper (as at 15 March 2021) which
is a good citation statistic for most papers, but is low considering the
millions of papers that use statistical analysis.

Two statisticians on this paper (AB and NW) have heard researchers admit
that they have copied-and-pasted their statistical methods sections from
other papers, regardless of whether they are appropriate. The aim of
this paper is to use text-mining methods to estimate the extent that
researchers are using cut-and-paste or `boilerplate' statistical methods
sections. Boilerplate text is that ``which can be reused in new contexts
or applications without significant changes to the original''
\citep{Wikipedia}. Use of these methods sections indicates that little
thought has gone into the statistical analysis.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\subsection{Data sources}

We used two openly available data sources to find statistical methods
sections: research articles published in \emph{PLOS ONE} and study
protocols registered on the Australian and New Zealand Clinical Trials
Registry (ANZCTR). Data sources were chosen as examples of common
research outputs that include descriptions of statistical methods that
were used, or are planned, for analysing study outcomes.

\subsubsection{Public Library of Science (PLOS ONE)}
\label{sec:methodsPLOS}

\emph{PLOS ONE} is a large open access journal that publishes original
research across a wide range of scientific fields. Articles must be in
English. Article submissions are handled by an academic editor who
selects peer reviewers based on their self-nominated areas of expertise.
Submissions do not undergo formal statistical review. Instead, reviewers
are required to assess submissions against several publication criteria,
including whether: ``Experiments, statistics, and other analyses are
performed to a high technical standard and are described in sufficient
detail'' \citep{PLOS}. All reviewers are asked the question: ``Has the
statistical analysis been performed appropriately and rigorously?'',
with the possible responses of ``Yes'', ``No'' and ``I don't know''.

Authors are encouraged to follow published reporting guidelines such as
EQUATOR, to ensure that chosen statistical methods are appropriate for
the study design, and adequate details are provided to enable
independent replication of results.

All \emph{PLOS ONE} articles are freely accessible via the PLOS
Application Programming Interface (API). This enabled us to conduct
searches of full-text articles and analyse data on articles' text
content and general attributes such as publication date and field(s) of
research. To find papers with a statistical methods section we used
targeted API searches followed by article filtering based on section
headings. The data were downloaded on 3 July 2020.

\emph{Step 1}: Targeted API searches. API searches were completed using
the R package `rplos' \citep{rplos}. Search queries targeted the
presence of analysis-related terms anywhere in the article. Search terms
combined the words ``data'' or ``statistical'' with one of:
``analysis'', ``analyses'', ``method'', ``methodology'' or
``model(l)ing''. Search terms were intended to be broad whilst keeping
search results to a manageable number for full-text review (see Step 2).
By allowing terms to appear anywhere in the article, we accounted for
the possibility of relevant text being placed in different sections, for
example, in the \emph{Material and Methods} section versus
\emph{Results}. Search results were indexed by a unique Digital Object
Identifier (DOI). Attribute data collected per DOI included journal
volume and subject classification(s).

\emph{Step 2}: Partial matching on section headings. Full text XML data
for all search results were downloaded and combined into a single
dataset, organised by DOI and subsection heading(s). Since \emph{PLOS
ONE} does not prescribe standardised headings to preface statistical
methods sections, we performed partial matching on available headings
against frequently used terms in initial search results: `Statistical
analysis', `Statistical analyses', `Statistical method', `Statistics',
`Data analysis' and `Data analyses'. For records that did not pass this
second stage filter, we selected a random sample of XXX records and
reviewed where initial search terms appeared in the full-text, to
estimate the likely proportion of statistical methods sections that were
missed.

\subsubsection{Australia and New Zealand Clinical Trials Registry (ANZCTR)}
\label{sec:methodsANZCTR}

The ANZCTR was established in 2005 as part of a coordinated global
effort to improve research quality and transparency in clinical trials
reporting; observational studies can also be registered. All studies
registered on ANZCTR are publicly available and can be searched via an
online portal (\url{https://www.anzctr.org.au}).

Details required for registration follow a standardised template
\citep{ANZCTR}, which covers participant eligibility, the
intervention(s) being evaluated, study design and outcomes. The
information provided must be in English. Studies are not peer reviewed.

For the statistical methods section, researchers are asked to provide a
``brief description'' of the sample size calculations, statistical
methods and planned analyses, although this section is not compulsory
\citep{ANZCTR}. Studies are reviewed by ANZCTR staff for completeness of
key information, which does not include the completeness of the
statistical methods sections.

All studies available on ANZCTR were downloaded on 1 February 2020 in
XML format. We used all the text available in the ``Statistical
methods'' section. We also collated basic information about the study
including the study type (interventional or observational), submission
date, number of funders and target sample size. These variables were
chosen as we believed they might influence the completeness of the
statistical methods section, because we expected larger studies and
those with funding to be more complete, and we also were interested in
changes over time.

Studies prior to 2013 were excluded as the statistical methods section
appeared to be introduced in 2013. Some studies were first registered on
the alternative trial database \emph{clinicaltrials.gov} and then also
posted to ANZCTR. We excluded these studies because they almost all had
no completed statistical methods section as this section is not included
in \emph{clinicaltrials.gov}.

\subsection{Full-text processing}
\label{sec:methods-cleaning}

We applied the same text cleaning to both data sources. Text cleaning
aimed to standardise notation and statistical terminology, whilst
minimising changes to article style and formatting. \emph{R} code used
for data extraction and cleaning is available from
\url{https://github.com/agbarnett/stats_section}.

Mathematical notation including Greek letters was converted from Unicode
characters to plain text. For example, the Unicode characters
corresponding to \(\theta\) (\textless U+03B8\textgreater) were replaced
with `theta'. Similarly, common symbols outside of Unicode blocks
including `\%' (percent) and `\textless{}' (`less-than') were converted
into plain text using the `textclean' package \citep{textclean}. General
formatting was removed, this included carriage returns, punctuation
marks, in-text references (e.g.~``{[}42{]}'') centred equations, and
other non-ASCII characters. Text contained inside brackets was retained
to maximise content for analysis, with brackets removed.

We compiled an extensive list of statistical terms to standardise
descriptions of statistical methods reported across both datasets. An
initial list was compiled by calculating individual word frequencies and
identifying relevant terms that appeared at least 100 times. Further
terms were sourced from index searches of three statistics textbooks
\citep[\citet{Diggle2013},\citet{Bland2015}]{Dobson2018}. The final list
is provided as Supplementary Material. Plurals (e.g., `chi-squares')
unhyphenated (e.g., `chi square') and combined (e.g.~`chisquare') terms
were transformed to singular, hyphenated form (e.g., `chi-square').
Common statistical tests were also hyphenated (e.g., `hosmer lemeshow'
to `hosmer-lemeshow').

As a final step, common stop words including pronouns, contractions and
selected prepositions were removed. We retained selected stop words
that, if excluded, may have changed the context of statistical methods
being described, for example `between' and `against'.

\subsection{Clustering algorithm}

\emph{Details to come}

We applied the clustering algorithm to the cleaned dataset, varying the
number of clusters from 1 to 50.

Results were transformed to lower case for the clustering, but examples
are given using the original capitalisation.

For each dataset, records assigned to invididual clusters were examined
for evidence of boilerplate text in two ways. We first reviewed the top
ten results that represented the strongest matches to each cluster.
Records assigned to the same cluster were also compared by calculating
pairwise cosine similarities; higher scores denoted a higher degree of
similarity in text between a pair of records.

\subsection{Missing statistical methods sections}

The statistical methods section for the ANZCTR data was missing for some
studies and we examined if there were particular studies where this
section was more likely to be missing. We used four independent
variables of date, study type (observational or interventional), number
of funders and target sample size. We used a logistic regression model
fitted using a Bayesian paradigm. A small number of sections were
labelled as ``Not applicable'', ``Nil'' or ``None'' and we changed these
to missing.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{plos-one}{%
\subsection{\texorpdfstring{\emph{PLOS ONE}}{PLOS ONE}}\label{plos-one}}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{figures/plos.summary} 

}

\caption{\label{fig:plos-n}PLOS summary}\label{fig:unnamed-chunk-3}
\end{figure}

API searches returned 131,847 results (DOIs), of which 111,731 (85\%)
included a statistical methods section based on our search strategy. In
the final sample, 95,518 (85\%) DOIs returned an exact match against
common section headings: 64,133 for `statistical analysis', 13,380 for
`statistical analyses' and 13,627 for `data analysis'.

Among DOIs that did not meet the partial matching criteria, initial
search terms appeared in {[}TODO{]}.

Search results varied by journal volume (Figure \ref{fig:plos-n}A). The
total number of API search results peaked at volumes 8 (n = 19,045) and
9 (n = 19,045), corresponding to years 2013 and 2014. This trend aligned
with the total number of papers published in \emph{PLOS ONE} over the
same period. The percentage of records that included a statistical
methods section by volume based on our proposed matching criteria varied
between 64\% (volume 2) and 86\% (volume 9).

Statistical methods sections had a median length of 127 words and
inter-quartile range of 61 to 254 words (Figure \ref{fig:plos-n}B).
7,450 articles (7\%) had a statistical methods section of 500 words or
more. 19,461 articles (17\%) had sections with 50 words or less, equal
to the length of this paragraph.

All DOIs included Biology and life sciences (n = 107,584), Earth
sciences (n = 7,605) and/or Computer and information sciences (n =
5,190) in their top 3 subject classifications (Figure
\ref{fig:plos-n}C).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figures/plos.wordclouds} 

}

\caption{\label{fig:plos-clouds}Topic clouds for ten clusters for PLOS ONE (left) and ANZCTR (right)}\label{fig:unnamed-chunk-5}
\end{figure}

The topic clouds based on ten clusters are in
Figure\textasciitilde{}\ref{fig:plos-clouds}. Frequently occurring words
reflected the use of statistical software (Topics 3 and 5), descriptive
statistics (Topic 6), group based hypothesis testing (Topics 1 and 4)
and definitions of statistical significance (Topics\textasciitilde1 and
9). Statistical methods sections associated with regression (Topic 2)
and meta-analysis (Topic 7) were also identified.

\includegraphics[width=3.75in,height=2.75in,keepaspectratio]{asa_template_files/figure-latex/unnamed-chunk-6-1.png}

Topics related to the use of statistical software differentiated between
Prism GraphPad (Topic\textasciitilde3: n = 9,879; 8.8\%) and SPSS (Topic
5: n = 9,574; 8.6\%) . Manual review of results showed that nine out of
the ten top matching DOIs for Topic 3 stated the use of Prism GraphPad,
but did not specify which statistical methods were used. Top matching
sections for Topic 5 included information on SPSS version numbers and
definitions of statistical significance. Examples of boilerplate text
for selected topics are presented in Table
\ref{tab:plos-example-boilerplate}. Examples correspond to top ranking
DOIs, and DOIs with the higher number of matches based on cosine
similarity score greater than 0.8. Further results from cosine
similarity scores are provided in Supplementary File 2.

\includegraphics[width=8.00in,height=4.12in,keepaspectratio]{asa_template_files/figure-latex/unnamed-chunk-7-1.png}

Definitions of statistical significance featured strongly in Topic 1 (n
= 3,775) and Topic 9 (n = 6,104) combined with hypothesis testing for
comparing differences between two groups. Topic 1 reflected applications
of Student's t-test assuming a 5\% level of statistical significance.
Topic 9 referenced similar methods combined with multiple thresholds for
declaring statistical significance by asterisk: ``\(^{*}p<0.05\),
\(^{**}p<0.01\) and \(^{***}p<0.001\)''., a practice that has been
criticised {[}add wasserstein2019{]}.

Group-based hypothesis testing was a recurring theme across topics, with
text descriptions varying based on method(s) used. One-way analysis of
variance also featured strongly in Topic 4 (n = 10,163), with text
citing common methods for performing post-hoc multiple comparisons. Top
matching sections across these topics did not include definitions of
groups being compared.

Frequently occurring words in Topic 6 (n = 4,746) including `Mean', `SD'
and `SEM' reflected the use of descriptive statistics for summarising
continuous variables. Sections associated with this topic appeared to be
expanded versions of Topics 1 and 9, showing evidence of boilerplate
text in the form of descriptive statistics followed by hypothesis
testing using Student's t-test, Mann Whitney U or one-way analysis of
variance.

\subsection{ANZCTR}

We downloaded 28,008 studies. The numbers of excluded studies are shown
in Figure\textasciitilde{}\ref{fig:anzctr-missing}. Of the 12,700
included studies, 9,523 (75\%) had a statistical methods section.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figures/excluded_anzctr_missing} 

}

\caption{ANZCTR search results.}\label{fig:unnamed-chunk-8}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figures/anzctr.wordclouds} 

}

\caption{ANZCTR topic clouds.}\label{fig:unnamed-chunk-9}
\end{figure}

The median length of the section was 129 words with an inter-quartile
range of 71 to 219 words. Some methods sections were only one word,
including ``ANOVA'', ``t-test'', ``SPSS'' and even ``SSPS''.

The clustering algorithm found groups that were purely sample size
calculations (topic 2), pilot studies (topic 5), safety/tolerability
studies (topic 6) and repeated measures ANOVA (topic 10). There were
cases where the exact same method section had been re-used in a
different study.

We also found evidence of `boilerplate' sections clustered as topic 3,
example text

\textbf{Box x: Examples of boilerplate text from ANZCTR}

Topic 3

\begin{itemize}
\tightlist
\item
  ``Shapiro Wilk test was used as normality test. Continuous variables
  were compared using Student t-test and Mann-Whitney U test when the
  data were not normally distributed. Categorical variables were
  compared using Pearson's chi-squared test and Fisher's exact test.
  Paired data were analyzed using Paired t-test and Wilcoxon signed rank
  test when data were not normally distributed.''
\item
  ``Comparisons between categorical variables will be made either using
  chi square or Fisher exact test. Continuous data will be compared
  using the Student's t-test or Mann-Whitney U test. Two sided p values
  of less than 0.05 will be considered statistically significant.''
\end{itemize}

We examined if four study characteristics were associated with a missing
statistics section. The odds ratios and 95\% credible intervals are in
Table\textasciitilde X. Observational studies were less likely to have a
missing methods section compared with interventional studies. Missing
sections became less likely over time. Studies with more funders and a
larger target sample size were less likely to have a missing methods
section.

\includegraphics[width=4.66in,height=1.55in,keepaspectratio]{asa_template_files/figure-latex/unnamed-chunk-10-1.png}

\begin{itemize}
\tightlist
\item
  Final sample size
\end{itemize}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

The first line in many statistical analysis sections in \emph{PLOS ONE}
was the software used and some entire sections in ANZCTR only stated the
software, implying that the software is the most important detail. As
Doug Altman said, ``Many people think that all you need to do statistics
is a computer and appropriate software'' \citep{Altman1994}. This is far
from the truth, and whilst it is important for researchers to mention
the software and version used for reproducibility purposes, it is a
minor detail compared with detailing what methods were used and why.

A frequent theme in the boilerplate statistical methods is the
definition of statistical significance, nearly always using a p-value at
the 5\% level. This widespread use of statistical significance is
troubling giving the bright-line thinking it engenders
\citep{McShane2019} and the common misinterpretations of p-values
\citep{Goodman2008}.

Despite the extensive array of statistical tests available, many authors
are reporting the same few methods.

One reason these inadequate sections get published is that most journals
do not use statistical reviewers, despite empirical evidence showing
they improve manuscript quality \citep{Hardwicke2020}.

A related paper has criticised vague statistical methods sections
because they deprive readers and reviewers for the opportunity to
confirm that the appropriate methods were used \citep{Weissgerber2018}.
These authors checked hundreds of papers using ANOVA and found that 95\%
did not contain the information needed to determine what type of ANOVA
was performed. This lack of information could well be because the
authors used a boilerplate statistical methods section that was missing
key details.

If authors shared their code then this would provide an alternative
route for checking what statistical methods were used. This is not a
perfect solution, as we still want authors to accurately report their
methods, but it does increase transparency. However, a recent paper
found that code sharing was very low in biomedical papers, with just 2\%
of a sample of over 6,000 papers sharing code \citep{Serghiou2021}.

Many researchers are using lazy practice by copying a standard
``boilerplate'' statistical methods section, likely cut-and-pasting from
other researchers or projects. This is a strong sign of the ritualistic
practice of statistics where researchers go through the motions rather
than using conscientious practice \citep{Stark2018}. This is concerning
because using the wrong statistical methods can reduce the value of
study, or worse, invalidate the entire study. These mistakes are
avoidable and are wasting of thousands of hours of researchers' time and
the time of patients and volunteers. Poor statistical practice is a key
driver of the ongoing reproducibility crisis in science
\citep{Ioannidis2014}.

\hypertarget{limitations}{%
\subsection{Limitations}\label{limitations}}

We did not check whether papers used the correct methods, and for some
simple studies a `boilerplate' statistical methods might be adequate.

We examined papers where there was a statistics section, and we missed
papers that used statistical analysis but did not include a statistical
analysis section. Reiterate outcomes of random sample checking here.

We only examined one large journal and one trial registry and hence our
results may not be generalisable to all journals or registries,
especially those that consistently use a statistical reviewer.

We searched the full text of \emph{PLOS ONE} papers but not the
supporting information which may contain statistical methods sections
for some papers. The search terms we used to find statistical methods
appeared in the supporting information titles for xxx papers (x\%). We
did not include the supporting information because it is less structured
than the paper and could be in PDF or Word format.

\section{Supplementary}

\subsection{PLOS}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/supplementary/supp_plosone.50clusters} 

}

\caption{PLOS ONE clustering metrics.}\label{fig:unnamed-chunk-11}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/supplementary/plos.topicvalues} 

}

\caption{PLOS ONE topic values.}\label{fig:unnamed-chunk-12}
\end{figure}

\subsection{ANZCTR}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/supplementary/supp_anzctr.50clusters} 

}

\caption{ANZCTR clustering metrics.}\label{fig:unnamed-chunk-13}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{figures/supplementary/anzctr.topicvalues} 

}

\caption{ANZCTR topic values.}\label{fig:unnamed-chunk-14}
\end{figure}

\bibliographystyle{agsm}
\bibliography{references.bib}

\end{document}
